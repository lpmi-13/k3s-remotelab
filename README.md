# K3s Homelab

A GitOps-driven, single-node K3s homelab setup that's designed to be multi-node ready. This project includes ArgoCD as the core GitOps engine, Gitea for Git hosting, a Django REST Framework application, and a complete monitoring stack with Prometheus and Grafana.

## Architecture

- **GitOps-first**: ArgoCD manages all deployments with declarative configuration
- **Zero-trust networking**: Linkerd service mesh provides automatic mTLS for all service-to-service communication
- **Single-node first, multi-node ready**: Uses standard Kubernetes resources that scale naturally
- **Simple networking**: Uses path-based routing with Traefik for seamless access
- **Local storage**: Uses local-path provisioner for single-node, easily switchable to distributed storage
- **Continuous deployment**: Complete ArgoCD setup with App-of-Apps pattern for automated deployments

## Services

- **Linkerd**: Service mesh for automatic mTLS and observability
- **ArgoCD**: GitOps deployment management
- **Gitea**: Self-hosted Git service with PostgreSQL backend
- **Django**: REST Framework application with Redis caching
- **Prometheus**: Metrics collection and monitoring
- **Grafana**: Metrics visualization and dashboards

## Quick Start

### Prerequisites

- Ubuntu/Debian Linux (tested on Ubuntu 20.04+)
- At least 4GB RAM
- Docker installed and running
- Sudo access (for K3s installation only)

### Installation

```bash
# 1. Install K3s (one-time setup, requires sudo)
./scripts/install-k3s.sh

# 2. Deploy the complete stack (fully automated!)
./scripts/deploy-all.sh
```

The deployment script is:
- ✅ **Fully automated** - no user interaction required
- ✅ **No sudo required** - runs with user permissions
- ✅ **No persistent config changes** - uses temporary Docker config
- ✅ **Fully idempotent** - safe to run multiple times

**What it does:**
1. Cleans up any existing resources (can be skipped with `--skip-cleanup`)
2. Installs Linkerd service mesh with automatic mTLS for all services
3. Deploys all Kubernetes resources (ArgoCD, monitoring, infrastructure)
4. Waits for Gitea to be ready
5. Automatically creates Gitea admin user (username: `homelab`, password: `homelab`)
6. Initializes Django repository in Gitea with automated workflow
7. Pulls Django image from ghcr.io/lpmi-13/k3s-remotelab-django and pushes to Gitea registry
8. Deploys Django application with Linkerd sidecar injection

## Service Access

Once deployed, all services are available exclusively via **HTTPS** with self-signed certificates:

- **ArgoCD**: https://localhost/argocd
  - Username: `admin`
  - Password: Displayed at end of deployment
- **Gitea**: https://localhost/gitea
  - Username: `homelab`
  - Password: `homelab`
  - Container registry: https://localhost/v2
- **Django API**: https://localhost/django
  - Health check: `/django/api/health/`
  - System info: `/django/api/system/`
- **Prometheus**: https://localhost/prometheus
- **Grafana**: https://localhost/grafana (admin/admin)

**Security Note:**
- **mTLS encryption**: All service-to-service communication is automatically encrypted via Linkerd
- **HTTPS**: External access uses HTTPS with self-signed TLS certificates (auto-generated by Traefik)
- **HTTP redirect**: HTTP requests are automatically redirected to HTTPS
- You'll need to accept the certificate warning in your browser on first visit
- This provides zero-trust networking for local development; use proper certificates in production

### Container Registry

The Gitea container registry is configured automatically during deployment. The system pulls images from `ghcr.io/lpmi-13/k3s-remotelab-django` and caches them in the local Gitea registry.

**Automated Workflow:**
- On git push to main branch, Gitea Actions automatically:
  1. Pulls the latest image from `ghcr.io/lpmi-13/k3s-remotelab-django`
  2. Re-tags and pushes to Gitea registry
  3. Runs security scans with Trivy

**Manual Image Operations:**
```bash
# Login to registry (one-time)
echo 'homelab' | docker login localhost -u homelab --password-stdin

# Pull from ghcr.io
docker pull ghcr.io/lpmi-13/k3s-remotelab-django:latest

# Tag for Gitea registry
docker tag ghcr.io/lpmi-13/k3s-remotelab-django:latest localhost/homelab/django-app:v2

# Push to registry
docker push localhost/homelab/django-app:v2

# Update deployment to use new tag
kubectl set image deployment/django django=localhost/homelab/django-app:v2 -n applications
```

See `docs/CONTAINER_REGISTRY_SETUP.md` for detailed instructions.

### Verifying mTLS

To verify that mTLS is enabled for all services:

```bash
# Add Linkerd CLI to PATH
export PATH=$PATH:~/.linkerd2/bin

# Check which pods have Linkerd proxies (look for 2/2 containers - app + linkerd-proxy)
kubectl get pods -n applications
kubectl get pods -n monitoring
kubectl get pods -n argocd

# Install Linkerd viz extension for observability dashboard
linkerd viz install | kubectl apply -f -
linkerd viz check

# Launch Linkerd dashboard to see live mTLS traffic
linkerd viz dashboard

# Check mTLS status for a specific deployment
linkerd viz stat deployment/django -n applications

# View live traffic between services
linkerd viz tap deployment/django -n applications
```

All pods in the `applications`, `monitoring`, and `argocd` namespaces will have a Linkerd sidecar proxy automatically injected. This proxy handles:
- **Automatic mTLS**: All TCP connections are transparently encrypted
- **Traffic metrics**: Request rates, latencies, and success rates
- **Load balancing**: Client-side load balancing with automatic retries
- **Circuit breaking**: Automatic failure detection and recovery

**Note:** Kubernetes Jobs (like `gitea-init-user`) are excluded from Linkerd injection using `linkerd.io/inject: disabled` annotation, as sidecars don't automatically terminate when Jobs complete. All long-running services have mTLS enabled.

## Directory Structure

```
├── manifests/              # Kubernetes manifests
│   ├── service-mesh/       # Linkerd control plane
│   ├── infrastructure/     # Ingress and core services
│   ├── monitoring/         # Prometheus + Grafana
│   ├── gitops/            # ArgoCD configuration
│   └── applications/       # Gitea + Django + dependencies
├── argocd-apps/           # ArgoCD Application definitions
│   ├── infrastructure/    # Infrastructure apps
│   └── applications/      # Service apps
├── config/                # Environment-specific configurations
│   ├── values-single-node.yaml
│   └── values-multi-node.yaml
└── scripts/               # Deployment scripts
```

## Multi-Node Migration

To migrate to a multi-node setup:

1. **Install distributed storage** (Longhorn recommended):
   ```bash
   kubectl apply -f https://raw.githubusercontent.com/longhorn/longhorn/master/deploy/longhorn.yaml
   ```

2. **Update storage class** in manifests:
   ```yaml
   storageClassName: "longhorn"  # instead of "local-path"
   ```

3. **Increase replica counts** for high availability:
   ```yaml
   replicas: 3  # instead of 1
   ```

4. **Add pod anti-affinity** rules for workload distribution

## Configuration

### Single-Node Configuration

Uses `config/values-single-node.yaml`:
- Single replicas for all services
- Local-path storage
- Conservative resource limits

### Multi-Node Configuration

Uses `config/values-multi-node.yaml`:
- Multiple replicas for HA
- Distributed storage (Longhorn/NFS)
- Higher resource limits
- Pod anti-affinity rules

## Monitoring

### Prometheus Targets

- Kubernetes API server
- Kubernetes nodes
- All pods with `prometheus.io/scrape: "true"` annotation
- Gitea metrics endpoint
- Django metrics endpoint

### Grafana Dashboards

- Kubernetes cluster overview
- Node resource utilization
- Pod metrics
- Application-specific dashboards

## Security Features

### Current Security Posture

✅ **Implemented:**
- **mTLS for all service-to-service communication** via Linkerd service mesh
- **HTTPS for all external access** with automatic HTTP redirect
- **Zero-trust networking** - all pod-to-pod traffic is encrypted by default
- **Service authentication** via mutual TLS certificates managed by Linkerd

⚠️ **Development Defaults (change in production!):**
- Default passwords (homelab/homelab for Gitea, admin/admin for Grafana)
- Self-signed certificates for external TLS
- Minimal RBAC configurations
- No authentication on some internal services

## Development

### Django Application

The Django app includes:
- REST API with health checks
- Redis integration for caching
- Prometheus metrics export
- Basic system information endpoint

### Adding New Services

1. Create manifests in appropriate directory
2. Add ingress rules if needed
3. Create ArgoCD Application definition
4. Update monitoring configuration

## Troubleshooting

### Deployment Issues

If something goes wrong during deployment, simply re-run the script:
```bash
./scripts/deploy-all.sh
```

The script will automatically clean up and redeploy everything. To keep existing resources and just update:
```bash
./scripts/deploy-all.sh --skip-cleanup
```

### Service Not Starting
```bash
kubectl describe pod <pod-name> -n <namespace>
kubectl logs <pod-name> -n <namespace>
```

### Storage Issues
```bash
kubectl get pv,pvc -A
kubectl describe pvc <pvc-name> -n <namespace>
```

### Network Issues
```bash
kubectl get ingress -A
kubectl describe ingress <ingress-name> -n <namespace>
```

### ArgoCD Issues
```bash
kubectl get applications -n argocd
kubectl describe application <app-name> -n argocd
```

### Complete Reset

To completely reset the cluster:
```bash
# Uninstall K3s
sudo /usr/local/bin/k3s-uninstall.sh

# Reinstall and redeploy
./scripts/install-k3s.sh
./scripts/deploy-all.sh
```

## Contributing

1. Follow the existing patterns for new services
2. Ensure multi-node compatibility
3. Add monitoring for new services
4. Update documentation

## License

MIT License - see LICENSE file for details